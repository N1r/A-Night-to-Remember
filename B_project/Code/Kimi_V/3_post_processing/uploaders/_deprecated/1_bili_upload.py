import os
import shutil
import json
import random
import yaml
import requests
import pandas as pd
import re
from datetime import datetime, timedelta, timezone
from pathlib import Path
from PIL import Image, ImageDraw, ImageFont, ImageFilter
from tqdm import tqdm
from fuzzywuzzy import fuzz  # ä¿æŒåŸä»£ç çš„ fuzzywuzzyï¼Œä¹Ÿå¯ä»¥æ¢æˆ rapidfuzz
from deep_translator import GoogleTranslator

# é…ç½® Gemini API
# å»ºè®®ç›´æ¥åœ¨ä»£ç é‡Œå®šä¹‰æˆ–ä»ç¯å¢ƒå˜é‡è¯»å–
GEMINI_API_KEY = "AIzaSyCYRSZcU_7B0EmZkr1p5Z9LrdiPC4A5xbw" 
# å°è¯•å¯¼å…¥ jieba è¿›è¡Œæ™ºèƒ½åè¯è¯†åˆ«
try:
    import jieba
    import jieba.posseg as pseg
    HAS_JIEBA = True
except ImportError:
    HAS_JIEBA = False
    print("ğŸš© æç¤ºï¼šæœªå®‰è£… jiebaï¼Œå°†ä½¿ç”¨åŸºç¡€éšæœºé€»è¾‘ã€‚å»ºè®®è¿è¡Œ 'pip install jieba'")

# ==================== å…¨å±€å¸¸é‡ä¸é…ç½® ====================
# è·å–é¡¹ç›®æ ¹ç›®å½•
PROJECT_ROOT = os.path.dirname(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
OUTPUT_DIR = os.path.join(PROJECT_ROOT, 'storage', 'ready_to_publish')
COVER_SUFFIX = '.jpg'
NEW_COVER_SUFFIX = '.jpg' # å·²ç»ç”± file_movie_topic æ•´ç†å¥½

TARGET_WIDTH = 1920
TARGET_HEIGHT = 1080
TAG = ['æ¯æ—¥è‹±è¯­æ–°é—»', 'è‹±è¯­æ–°é—»', 'è‹±è¯­å­¦ä¹ ', 'å·æ™®', 'é©¬æ–¯å…‹', 'å’¨è¯¢ç›´é€šè½¦', 'ç¤¾ä¼šè§‚å¯Ÿå±€', 'çƒ­ç‚¹æ·±åº¦è§‚å¯Ÿ']

# #API é…ç½®
# API_KEY = 'sk-2hQb4lo4JuCdWWCflcN41jddIIQzhtSi78Qeb7vWOM40XSkJ'
# API_BASE_URL = 'https://api.302.ai'
# API_MODEL = 'Doubao-Seed-2.0-lite'


API_KEY = 'ak_1lt5CC7fR0YP9l47On12532E7b78k'
API_BASE_URL = 'https://api.longcat.chat/openai'
#API_MODEL = 'LongCat-Flash-Thinking'
API_MODEL = 'LongCat-Flash-Chat'
#API_MODEL = 'LongCat-Flash-Lite'



# è§†è§‰è§„èŒƒ
HIGHLIGHT_COLOR = "#FFD700"  # å“ç‰Œé‡‘é»„
NORMAL_COLOR = "#FFFFFF"     # çº¯ç™½
BG_BOX_COLOR = (0, 0, 0, 230) # é»‘è‰²åŠé€æ˜èƒŒæ™¯å—
RED_ACCENT = "#E21918"       # æ ‡å¿—æ€§æ–°é—»çº¢

# è‡ªåŠ¨é€‰æ‹©å­—ä½“
def get_font_path():
    possible_fonts = [
        "/root/VideoLingo/batch/Fonts/HYWenHei-65W.ttf",
        "/usr/share/fonts/google-noto-cjk/NotoSansCJK-Bold.ttc",
        "SourceHanSansSC-Bold.otf",
        "SimHei.ttf",
        "arial.ttf"
    ]
    for fp in possible_fonts:
        if os.path.exists(fp): return fp
    return "arial.ttf"

FONT_PATH = get_font_path()
print(f"ã€ç³»ç»Ÿã€‘ä½¿ç”¨å­—ä½“: {FONT_PATH}")

# ==================== 0. æ–°å¢ï¼šä¿¡æ¯æå–å·¥å…· (æ¥è‡ªä»£ç 2) ====================

def simple_read_topic(file_path: str) -> list:
    """è¯»å– gpt_log ä¸‹çš„ summary.json è·å– topic"""
    if not os.path.exists(file_path):
        return []
    try:
        with open(file_path, 'r', encoding='utf-8') as f:
            data = json.load(f)
        # å…¼å®¹åˆ—è¡¨æˆ–å­—å…¸ç»“æ„
        if isinstance(data, list):
            return [item['response']['topic'] for item in data if 'response' in item and 'topic' in item['response']]
        elif isinstance(data, dict) and 'response' in data and 'topic' in data['response']:
             return [data['response']['topic']]
        return []
    except Exception as e:
        print(f"âš ï¸ è¯»å– Topic å¤±è´¥: {e}")
        return []

def quick_read_srt(file_path: str) -> str:
    """æç®€è¯»å– SRT çº¯æ–‡æœ¬"""
    with open(file_path, 'r', encoding='utf-8-sig', errors='ignore') as f:
        content = f.read()
    
    # åŒ¹é…æ—¶é—´è½´çš„æ­£åˆ™
    pattern = r'\d{2}:\d{2}:\d{2},\d{3} --> \d{2}:\d{2}:\d{2},\d{3}'
    
    # ä¸€è¡Œæå®šï¼šè¿‡æ»¤ç©ºè¡Œã€æ•°å­—è¡Œã€æ—¶é—´è¡Œ
    lines = [
        line.strip() for line in content.splitlines() 
        if line.strip() and not line.strip().isdigit() and not re.match(pattern, line)
    ]
    
    return "\n".join(lines)
def find_channel_by_fuzzy_match(excel_path: str, target_title: str, min_similarity=80):
    """æ ¹æ®æ–‡ä»¶å¤¹åæ¨¡ç³ŠåŒ¹é… Excel ä¸­çš„é¢‘é“å"""
    if not os.path.exists(excel_path):
        print(f"âš ï¸ æœªæ‰¾åˆ° {excel_path}ï¼Œè·³è¿‡é¢‘é“åŒ¹é…")
        return None
    try:
        df = pd.read_excel(excel_path)
        if 'title' not in df.columns or 'channel_name' not in df.columns:
            print("âš ï¸ Excel ç¼ºå°‘ 'title' æˆ– 'channel_name' åˆ—")
            return None
        
        best_match, best_score = None, 0
        for _, row in df.iterrows():
            current_title = str(row['title'])
            # ä½¿ç”¨ fuzzywuzzy çš„ ratio
            similarity = fuzz.ratio(target_title.lower(), current_title.lower())
            if similarity > best_score and similarity >= min_similarity:
                best_score, best_match = similarity, row['channel_name']
        
        if best_match:
            # print(f"âœ… é¢‘é“åŒ¹é…æˆåŠŸï¼ˆ{best_score}%ï¼‰ï¼š'{best_match}'")
            return best_match
        else:
            return None
    except Exception as e:
        print(f"âŒ é¢‘é“åŒ¹é…å‡ºé”™: {e}")
        return None

# ==================== 1. æ™ºèƒ½é«˜äº®é€»è¾‘ (é¿å¼€è™šè¯) ====================

def get_random_noun_highlight(text):
    """æå–æ ‡é¢˜ä¸­çš„æ ¸å¿ƒåè¯å®ä½“ï¼Œé¿å¼€è™šè¯"""
    # ç§»é™¤ [é¢‘é“å] å¹²æ‰°
    clean_text = re.sub(r'\[.*?\]', '', text)
    
    if HAS_JIEBA:
        words = pseg.cut(clean_text)
        nouns = [w.word for w in words if w.flag in ['n', 'nr', 'ns', 'nt', 'nz'] and len(w.word) > 1]
        if nouns:
            return random.choice(nouns)
    
    STOP_WORDS = ["çš„", "äº†", "åœ¨", "æ˜¯", "è¢«", "å·²ç»", "ä¸ä»…", "ç”šè‡³", "è€Œä¸”"]
    parts = re.findall(r'[\u4e00-\u9fa5]{2,4}', clean_text)
    valid_parts = [p for p in parts if p not in STOP_WORDS]
    
    return random.choice(valid_parts) if valid_parts else None

# ==================== 2. å°é¢ç»˜å›¾æ ¸å¿ƒ (ç²¾å‡†å¯¹é½) ====================

def wrap_text_styled(text, font, max_width):
    lines = []
    current_line = ""
    for char in text:
        if font.getlength(current_line + char) <= max_width:
            current_line += char
        else:
            lines.append(current_line)
            current_line = char
    lines.append(current_line)
    return lines[:2] 

def draw_text_line_centered(draw, line, font, x_start, y_top, box_height, highlight_word):
    left, top, right, bottom = font.getbbox(line)
    text_height = bottom - top
    vertical_center_offset = (box_height - text_height) // 2 - top
    draw_y = y_top + vertical_center_offset

    if not highlight_word or highlight_word not in line:
        draw.text((x_start, draw_y), line, font=font, fill=NORMAL_COLOR)
        return

    parts = line.split(highlight_word, 1)
    current_x = x_start
    draw.text((current_x, draw_y), parts[0], font=font, fill=NORMAL_COLOR)
    current_x += font.getlength(parts[0])
    draw.text((current_x, draw_y), highlight_word, font=font, fill=HIGHLIGHT_COLOR)
    current_x += font.getlength(highlight_word)
    draw.text((current_x, draw_y), parts[1], font=font, fill=NORMAL_COLOR)


def cover_making(image_path, output_path, translated_text, logo_path='figure.png'):
    # å‡è®¾å®šä¹‰çš„å…¨å±€å˜é‡ï¼Œå¦‚æœæ²¡æœ‰è¯·åœ¨å‡½æ•°å†…å®šä¹‰
    TARGET_WIDTH = 1920
    TARGET_HEIGHT = 1080
    try:
        # 1. å¤„ç†èƒŒæ™¯å›¾
        bg = Image.open(image_path).convert('RGBA')
        bg = bg.resize((TARGET_WIDTH, TARGET_HEIGHT), Image.Resampling.LANCZOS)
        bg = bg.filter(ImageFilter.GaussianBlur(radius=2))
        
        # 2. è’™å±‚å åŠ 
        overlay = Image.new('RGBA', (TARGET_WIDTH, TARGET_HEIGHT), (0, 0, 0, 60))
        canvas = Image.alpha_composite(bg, overlay)
        
        # 3. --- æ–°å¢ï¼šè‡ªé€‚åº”ç¼©æ”¾å¹¶åµŒå…¥ Logo ---
        if logo_path:
            logo = Image.open(logo_path).convert('RGBA')
            orig_w, orig_h = logo.size
            
            # è®¾å®š Logo å æ®èƒŒæ™¯å®½åº¦çš„æ¯”ä¾‹ (ä¾‹å¦‚ 20%)
            logo_target_width = int(TARGET_WIDTH * 0.2)
            # è®¡ç®—ç­‰æ¯”ä¾‹ç¼©æ”¾åçš„é«˜åº¦
            logo_target_height = int(orig_h * (logo_target_width / orig_w))
            
            # æ‰§è¡Œ Resize
            logo = logo.resize((logo_target_width, logo_target_height), Image.Resampling.LANCZOS)
            
            # è®¾ç½®è¾¹è· (Margin)
            margin = 40
            # ç²˜è´´åˆ°å·¦ä¸Šè§’ï¼Œ(x, y) = (margin, margin)
            # æœ€åçš„ logo å‚æ•°ä½œä¸º mask å¿…ä¸å¯å°‘ï¼Œå¦åˆ™é€æ˜éƒ¨åˆ†ä¼šé»‘æ¡†
            canvas.paste(logo, (margin, margin), logo)

        # 4. ä¿å­˜ç»“æœ
        # æ³¨æ„ï¼šJPEG ä¸æ”¯æŒé€æ˜åº¦ï¼Œæ‰€ä»¥ä¿å­˜å‰è½¬ä¸º RGB
        canvas.convert('RGB').save(output_path, quality=95)
        print(f"âœ… æˆåŠŸç”Ÿæˆå¸¦ Logo å°é¢: {output_path}")

    except Exception as e:
        print(f"âŒ å°é¢å¤±è´¥ {image_path}: {e}")


# ==================== 3. API ç¿»è¯‘é€»è¾‘ (å·²å¢å¼º) ====================

def translate_with_api(text_content: str) -> str:
    """
    æ¥æ”¶åŒ…å« é¢‘é“åã€åŸæ ‡é¢˜ã€Topic çš„ç»¼åˆå­—ç¬¦ä¸²è¿›è¡Œå¤„ç†
    """
    headers = {"Authorization": f"Bearer {API_KEY}", "Content-Type": "application/json"}
    prompt = """
# Role

ä½ æ˜¯ä¸€åæ·±è€•â€œä»Šæ—¥å¤´æ¡â€ã€â€œè…¾è®¯æ–°é—»â€ã€â€œå‚è€ƒæ¶ˆæ¯â€ç­‰èµ„è®¯å¹³å°çš„èµ„æ·±æ”¿ç»ä¸»ç¬”ã€‚ä½ çš„ç›®æ ‡å—ä¼—æ˜¯bç«™ä¸­å›½ä¸­å¹´ç”·æ€§ç¾¤ä½“ï¼Œå…³æ³¨å¤§å›½åšå¼ˆã€åœ°ç¼˜æ”¿æ²»ä¸å®è§‚ç»æµã€‚
ä½ çš„æ ¸å¿ƒèƒ½åŠ›æ˜¯ï¼šä»çç¢çš„å¤–åª’åŸå£°ä¸­ï¼Œæå–**æœ€å…·å†²å‡»åŠ›çš„æ ¸å¿ƒè§‚ç‚¹**ï¼Œå¹¶ä»¥â€œä¸€è¯­å®šä¹¾å¤â€çš„é£æ ¼é‡å¡‘æ ‡é¢˜ã€‚
ä½ çš„æ ¸å¿ƒç‰¹è´¨æ˜¯ï¼šç«‹åœºåšå®šï¼Œè§†é‡å®é˜”ã€‚ ä½ èƒ½ä»çº·ç¹å¤æ‚çš„å¤–åª’ä¿¡æ¯ä¸­ï¼Œä¸€çœ¼æ´ç©¿å…¶å™äº‹é™·é˜±ï¼Œå¹¶ä»¥ç¬¦åˆä¸­å›½å›½å®¶åˆ©ç›Šã€ç»´æŠ¤å¤šæåŒ–ç§©åºçš„è§†è§’è¿›è¡Œé‡å†™ã€‚

# Input Data
* åŸæ ‡é¢˜ï¼š{folder_name}
* è®¨è®ºä¸»é¢˜ï¼š{topic_list}
* å­—å¹•å†…å®¹ï¼š{srt_list}

# Construction Rules (ç¡¬æ ¸æ”¿ç»çˆ†æ¬¾æ³•åˆ™)

1. **ç»“æ„åŒ–å‘ˆç°ï¼ˆæ ¸å¿ƒçº¢çº¿ï¼‰ï¼š**
* **å›ºå®šæ ¼å¼ï¼š â€œä¸€å¥æ ¸å¿ƒè¯­å½•â€ å…³é”®äººç‰©ï¼Œäº‹ä»¶çš„ç®€çŸ­å®šæ€§æè¿°ã€‚**
* è¯­å½•å¿…é¡»æ‘˜è‡ªå­—å¹•ï¼Œä»£è¡¨å…¶æ ¸å¿ƒç«‹åœºæˆ–æœ€éœ‡æ’¼çš„ç»†èŠ‚ã€‚
* ä¸¥ç¦ç©ºæ´ï¼Œæ ‡é¢˜ä¸­å¿…é¡»åŒ…å«å…·ä½“çš„â€œå®ä½“åè¯â€ï¼ˆå¦‚æ³•æ¡ˆåã€å›½å®¶ã€ç‰¹å®šæ•°æ®ï¼‰ã€‚

3. **è§†è§‰ä¸ç¬¦å·çº¦æŸï¼š**
* **ä¸¥ç¦ä½¿ç”¨åŠè§’ç¬¦å·**ï¼ˆå¦‚ : , " " ï¼‰ï¼Œå¿…é¡»ä½¿ç”¨å…¨è§’ç¬¦å·ï¼ˆå¦‚ ï¼š ï¼Œ â€œâ€ ï¼‰ã€‚
* å…¨æ–‡ä¸¥ç¦è¶…è¿‡35å­—ã€‚
* ä»…è¾“å‡ºæ ‡é¢˜ä¸€è¡Œï¼Œä¸è¦ä»»ä½•è§£é‡Šã€‚
Workflow
è¿‡æ»¤ä¸æå–ï¼š ä»å­—å¹•ä¸­å‰”é™¤ä¿®é¥°æ€§åºŸè¯ï¼Œé”å®šé‚£å¥æœ€å…·â€œå¯¹æŠ—æ€§â€æˆ–â€œæ‰¿è®¤å¤±è´¥â€çš„æ ¸å¿ƒåŸè¯ã€‚

æ„å›¾æ ¡å‡†ï¼š åˆ†æè¯¥äººç‰©è¯´è¯çš„çœŸå®æ„å›¾â€”â€”æ˜¯æå“ã€æ˜¯ç”©é”…ã€è¿˜æ˜¯æˆ˜ç•¥é€€ç¼©ï¼Ÿ

é‡ç»„å®šè°ƒï¼š æŒ‰ç…§å…¬å¼è£…é…ã€‚ç¡®ä¿â€œé‡‘å¥â€æŠ“çœ¼ï¼Œâ€œå®šæ€§â€æ‰å¿ƒã€‚

æœ€ç»ˆå®¡æ ¡ï¼š æ£€æŸ¥ç¬¦å·æ˜¯å¦å…¨è§’ï¼Œè¯­æ°”æ˜¯å¦åƒä¸€ä½èµ„æ·±æ”¿ç»è§‚å¯Ÿå‘˜åœ¨è¿›è¡Œå†…éƒ¨åˆ†æã€‚

Examples
âœ… è´æ£®ç‰¹ï¼šâ€œ20ï¼…å…³ç¨æ˜¯é‡å¡‘è´¸æ˜“éœ¸æƒçš„æ ¸å¿ƒåº•ç‰Œâ€ æ‰§æ„æ¨åŠ¨æ¿€è¿›æ‰©å¼ ã€‚
âœ… èˆ’é»˜ï¼šâ€œèŠ¯ç‰‡æ³•æ¡ˆçš„æ¯ä¸€åˆ†é’±éƒ½å¿…é¡»æœåŠ¡äºéåˆ¶æˆ˜ç•¥â€ æš´éœ²ç¾å¼ç§‘æŠ€éœ¸æƒåº•è‰²ã€‚
âœ… æ™®äº¬ï¼šâ€œä¹Œå…‹å…°å…¥çº¦å³æ„å‘³ç€å…¨çƒæˆ˜ç•¥å¹³è¡¡çš„ç»ˆç»“â€ ä¸¥å‰è­¦å‘Šåœ°ç¼˜å®‰å…¨æœ€åçº¢çº¿ã€‚
âœ… é©¬æ–¯å…‹ï¼šâ€œæ”¿åºœè¡¥è´´è‹¥è„±ç¦»æ•ˆç‡å°†æ²¦ä¸ºæ”¿å®¢çš„æ•°å­—æ¸¸æˆâ€ æ·±åº¦æ‹†è§£ç¾äº§ä¸šæ”¿ç­–å›°å±€ã€‚

# Workflow
1. **æ‰«è§†æå–ï¼š** ä»å­—å¹•ä¸­é”å®šé‚£å¥æœ€èƒ½ä»£è¡¨äººç‰©ç«‹åœºã€æœ€ç‹ ã€æˆ–è€…åŒ…å«å…³é”®æ•°æ®çš„â€œæ ¸å¿ƒåŸè¯â€ã€‚
2. **èº«ä»½é”å®šï¼š** æå–å…³é”®äººç‰©åŠä¸å…¶ç›¸å…³çš„æ ¸å¿ƒåŠ¨ä½œ/äº‹ä»¶ã€‚
3. ç»“æ„è£…é…ï¼š ä¸¥æ ¼æŒ‰ç…§ äººç‰©ï¼šâ€œè¯­å½•â€ æè¿° çš„å…¬å¼è¿›è¡Œç»„è£…ã€‚
4. ç«‹åœºæ ¡å‡†ï¼š æ£€æŸ¥æªè¾æ˜¯å¦ç¬¦åˆä¸­å›½è¯»è€…çš„æ”¿ç»å®¡ç¾ä¸ç«‹åœºå–å‘ï¼Œç¡®ä¿æ–‡å­—è€è¾£ã€ä¸“ä¸šã€‚

"""
    data = {
        "model": API_MODEL,
        "messages": [
            {"role": "system", "content": prompt},
            {"role": "user", "content": text_content}
        ],
    }
    try:
        response = requests.post(f"{API_BASE_URL}/v1/chat/completions", headers=headers, json=data, timeout=30)
        return response.json()["choices"][0]["message"]["content"].strip()
    except Exception as e:
        print(f"API Error: {e}")
        return None

# ==================== 4. ä¸šåŠ¡å¤„ç†é€»è¾‘ (æ•´åˆäº† Topic å’Œ Channel) ====================

def generate_titles(video_paths: list) -> tuple:
    titles, translated_texts = [], []
    
    print(f"ğŸ” å¼€å§‹ç”Ÿæˆæ ‡é¢˜ï¼Œå…± {len(video_paths)} ä¸ªè§†é¢‘...")
    
    for video_path in video_paths:
        folder_path = os.path.dirname(video_path)
        folder_name = os.path.basename(folder_path)
        
        # --- æ•´åˆé€»è¾‘å¼€å§‹ ---
        # 1. è·å– Topic
        json_path = os.path.join(folder_path, 'gpt_log', 'summary.json')
        topic_list = simple_read_topic(json_path)
        srt_path = os.path.join(folder_path, 'trans.srt')
        srt_list = quick_read_srt(srt_path)
        #print(srt_list)
        # 2. è·å– Channel Name
        channel_name = find_channel_by_fuzzy_match('tasks_setting.xlsx', folder_name) or "ç²¾é€‰æ–°é—»"
        
        # 3. æ„é€ å‘é€ç»™ API çš„å†…å®¹
        #prompt_content = f"é¢‘é“åä¸ºï¼š{channel_name}\nåŸæ ‡é¢˜ä¸º:{folder_name}\nå†…å®¹ä¸»é¢˜ä¸º:{topic_list}å®Œæ•´å­—å¹•: {srt_list}"
        prompt_content = f"é¢‘é“åä¸ºï¼š{channel_name}\nåŸæ ‡é¢˜ä¸º:{folder_name}\nå†…å®¹ä¸»é¢˜ä¸º:{topic_list}å®Œæ•´å­—å¹•: {srt_list}"

        # print(f"  > å¤„ç†: {folder_name} | é¢‘é“: {channel_name}")
        # --- æ•´åˆé€»è¾‘ç»“æŸ ---

        translated = None
        max_retries = 3

        # --- 1. API é‡è¯•å¾ªç¯ ---
        for i in range(max_retries):
            try:
                # å°è¯•è°ƒç”¨ API
                translated = translate_with_api(prompt_content)
                # å¦‚æœæ‹¿åˆ°äº†ç»“æœï¼Œç›´æ¥è·³å‡ºé‡è¯•å¾ªç¯
                if translated:
                    print(f"  âœ… API ç¬¬ {i+1} æ¬¡è°ƒç”¨æˆåŠŸ")
                    break
            except Exception as e:
                print(f"  âš ï¸ ç¬¬ {i+1} æ¬¡å°è¯•å¤±è´¥: {e}")
            
            if i < max_retries - 1:
                import time
                time.sleep(2)

        # --- 2. ç¡®å®š raw_translated_title (æ— è®º API æ˜¯å¦æˆåŠŸ) ---
        # åˆå§‹ä¿åº•ï¼šå…ˆå®šä¸ºæ–‡ä»¶å¤¹å
        raw_translated_title = folder_name 

        if translated:
            # API æˆåŠŸäº†ï¼Œä½¿ç”¨ API çš„ç»“æœ
            raw_translated_title = translated
        else:
            # API å½»åº•å¤±è´¥ï¼Œå¯ç”¨ Google ç¿»è¯‘å…œåº•
            print("  âš ï¸ API æ‰€æœ‰å°è¯•å‡å¤±è´¥ï¼Œå°è¯• Google ç¿»è¯‘...")
            try:
                translated_res = GoogleTranslator(source='auto', target='zh-CN').translate(folder_name)
                raw_translated_title = translated_res
                print(f"  âœ… Google ç¿»è¯‘å…œåº•æˆåŠŸ: {raw_translated_title}")
            except Exception as ge:
                print(f"  âŒ Google ç¿»è¯‘ä¹Ÿå¤±è´¥äº†: {ge}ï¼Œä½¿ç”¨åŸå§‹æ–‡ä»¶å¤¹å")
                # æ­¤æ—¶ raw_translated_title ä¾ç„¶æ˜¯åˆå§‹çš„ folder_name

        # --- 3. æœ€ç»ˆç»“æœæ¸…æ´—ä¸ä¿å­˜ ---
        # æŠŠæœ€ç»ˆç¡®å®šçš„æ ‡é¢˜å­˜å…¥åˆ—è¡¨
        translated_texts.append(raw_translated_title)

        # æ¸…æ´—æ ‡é¢˜ï¼ˆå»æ‰æ‰€æœ‰æ‹¬å·åŠå…¶å†…å®¹ï¼Œå¦‚ [AI] ç­‰ï¼‰
        # è¿™é‡Œä½¿ç”¨ raw_translated_title è€Œä¸æ˜¯ translatedï¼Œé˜²æ­¢ None æŠ¥é”™
        clean_t = re.sub(r'[\[ã€].*?[\]ã€‘]', '', raw_translated_title).strip()
        
        # ç»„è£… B ç«™æ ‡é¢˜ï¼Œç¡®ä¿ä¸è¶…è¿‡é•¿åº¦é™åˆ¶
        final_title = f"[ç†Ÿè‚‰]{clean_t}"
        titles.append(final_title[:80]) # B ç«™æ ‡é¢˜ä¸Šé™é€šå¸¸æ˜¯ 80 å­—ç¬¦        
        print(f" âœ… ç”Ÿæˆæ ‡é¢˜: {final_title}")

    return titles, translated_texts

# ==================== é…ç½®ï¼šæ–‡æ¡ˆä¸æ ‡ç­¾ (å˜²è®½/åƒç“œé£æ ¼) ====================

# ç®€ä»‹æ¨¡æ¿åº“ï¼ˆéšæœºæŠ½å–ï¼Œä¿æŒæ–°é²œæ„Ÿï¼Œé¿å…æŸ¥é‡ï¼‰
DESC_TEMPLATES = [
    "ã€æ—¥å¸¸å›´è§‚ã€‘å¸¦å¤§å®¶çœ‹çœ‹å¯¹é¢åˆåœ¨æ•´ä»€ä¹ˆæ–°æ´»ã€‚ç¾å›½é‚£ç‚¹ä¸¤å…šæ‰¯çš®çš„ç ´äº‹å„¿ï¼Œå…¨åœ¨è§†é¢‘é‡Œäº†ã€‚æœ¬æ„æ˜¯ç»ƒå£è¯­ï¼Œç»“æœçœ‹ç€çœ‹ç€å‘ç°æ¯”ç”µè§†å‰§è¿˜ç²¾å½©ã€‚é€»è¾‘è‡ªç†ï¼Œçœ‹æˆéšæ„ã€‚ ğŸ³ï¸ å ä¸ªç”²ï¼šç´ æå…¨æ¬è‡ªå¤–åª’ï¼Œçº¯å±è¯­è¨€å­¦ä¹ å’Œå­¦æœ¯æ‰¹åˆ¤ï¼Œåˆ«é—®ï¼Œé—®å°±æ˜¯ä¸ºäº†å­¦ä¹ ã€‚ ğŸ“º è§‰å¾—æœ‰æ„æ€å°±éšæ‰‹ç»™ä¸ªä¸‰è¿ï¼Œéšç¼˜æ›´æ–°ï¼Œæ‡‚çš„éƒ½æ‡‚ã€‚",
    "âš¡ï¸ éšä¾¿èŠèŠï¼šç¾å¼æ”¿å›çš„å¤§æˆæ’æœŸä¸å¤§å‹åŒæ ‡ç°åœºã€‚ è¯´æ˜¯é«˜é˜¶åŒè¯­ç´ æï¼Œå…¶å®å°±æ˜¯å¸¦å¤§å®¶æ‹†è§£ä¸€ä¸‹é‚£å¥—è¯æœ¯é™·é˜±ï¼Œçœ‹æƒåŠ›çš„æ¸¸æˆæ€ä¹ˆç©å´©ç¤¾ä¼šå…±è¯†çš„ã€‚ ğŸ’¡ è¹²ä¸ªç‚¹ï¼šçœ‹ä»–ä»¬æ€ä¹ˆæŠŠé€»è¾‘ç©å‡ºèŠ±æ¥ã€‚ ğŸ¤ äº’åŠ¨ï¼šå¤§å®¶è¯„è®ºåŒºç†æ™ºåƒç“œï¼Œè¦æ˜¯è§‰å¾—è¿™æ³¢åˆ†æè¿˜ç®—èµ°å¿ƒï¼Œç‚¹ä¸ªèµæ”¯æŒä¸‹ï¼Œæ¯•ç«Ÿå‰ªè¾‘ä¹ŸæŒºè´¹å¤´å‘çš„ã€‚",
    "ğŸ‡ºğŸ‡¸ æ—¶ä»£å°æœ¬æœ¬ï¼šè¿™å¸®ç¾å›½æ”¿è¦åˆåœ¨æ¼”å“ªä¸€å‡ºï¼Ÿ ç¿»äº†ç‚¹ç¾åª’çš„çŠ€åˆ©åæ§½å’Œè¾©è®ºåŸå£°ï¼Œå­—å¹•å·²ç»ç²¾æ ¡è¿‡äº†ï¼Œæ–¹ä¾¿å¤§å®¶çœ‹æ¸…é‚£å¸®äººå˜´é‡Œçš„å¼¯å¼¯ç»•ã€‚ ğŸ¯ æ ¸å¿ƒçœ‹ç‚¹ï¼šæ—¥å¸¸äº’é»‘ | æ”¿ç­–ç”»é¥¼ | åª’ä½“å¤§å‹ç¿»è½¦ç°åœº ğŸ’¬ äº¤æµï¼šè¯„è®ºåŒºå¤§ç¥å¤šï¼Œæ¬¢è¿åœ¨çº¿å¼€è¯¾ã€‚æ„Ÿè°¢å„ä½æ§åœºï¼Œä¸‹æœŸè§ï¼ˆå¦‚æœæˆ‘ä¸é¸½çš„è¯ï¼‰ã€‚"
]

# è¡¥å……æ ‡ç­¾ï¼ˆé«˜çƒ­åº¦å…³é”®è¯ï¼‰
EXTRA_TAGS = "ç‰¹æœ—æ™®,ç¾å›½å¤§é€‰,å…±å’Œå…š,æ°‘ä¸»å…š,ç¾å¼ç¬‘è¯,åŒè¯­å­—å¹•,å¬åŠ›,å›½é™…æ—¶äº‹,åƒç“œ"

# ==================== æ ¸å¿ƒé€»è¾‘ï¼šYAML ç”Ÿæˆ ====================

def split_and_create_yaml(videos, covers, titles, dtimes, paid_ratio=0.1):
    """
    å°†è§†é¢‘åˆ—è¡¨éšæœºåˆ’åˆ†ä¸ºå…è´¹/ä»˜è´¹å†…å®¹ï¼Œå¹¶ç”Ÿæˆå¯¹åº”çš„ä¸Šä¼  YAML é…ç½®æ–‡ä»¶
    """
    total = len(videos)
    indices = list(range(total))
    random.shuffle(indices) # æ‰“ä¹±é¡ºåº
    
    # è®¡ç®—åˆ†å‰²ç‚¹
    split_point = int(total * (1 - paid_ratio))
    
    # --- å†…éƒ¨å‡½æ•°ï¼šå†™å…¥ YAML ---
    def write_yaml(sub_v, sub_c, sub_t, sub_dt, filename, is_paid):
        streamers = {}
        
        for i, (v, c, t, dt) in enumerate(zip(sub_v, sub_c, sub_t, sub_dt)):
            # 1. éšæœºé€‰æ‹©ç®€ä»‹æ¨¡æ¿
            base_desc = random.choice(DESC_TEMPLATES)
            
            # 2. ç»„åˆæœ€ç»ˆç®€ä»‹ (å°†æ ‡é¢˜æ”¾åœ¨ç¬¬ä¸€è¡Œï¼Œåˆ©äº SEO å’Œç”¨æˆ·å¿«é€Ÿé¢„è§ˆ)
            final_desc = f"â–º æœ¬æœŸçœ‹ç‚¹ï¼š{t}\n\n{base_desc}"
            
            # 3. å¤„ç†æ ‡ç­¾ (åˆå¹¶ Global TAG å’Œ EXTRA_TAGS)
            # æ­£ç¡®åˆå¹¶åˆ—è¡¨ TAG å’Œå­—ç¬¦ä¸² EXTRA_TAGS
            tag_list = TAG if isinstance(TAG, list) else [TAG]
            combined_tags = tag_list + EXTRA_TAGS.split(",")
            
            # å»é‡ã€å»ç©ºã€é™åˆ¶æ•°é‡ (Bç«™é™åˆ¶æ ‡ç­¾æ•°ï¼Œé€šå¸¸å–å‰12ä¸ª)
            final_tag_list = list(set([x.strip() for x in combined_tags if x.strip()]))
            final_tag = ",".join(final_tag_list[:12])

            # 4. æ„é€ å•ä¸ªè§†é¢‘çš„é…ç½®é¡¹
            entry = {
                "copyright": 1,           # 1=è‡ªåˆ¶ (ç¿»è¯‘äºŒåˆ›é€šå¸¸æŠ•è‡ªåˆ¶)
                "source": None,           # è‡ªåˆ¶æ— éœ€ source
                "tid": 208,               # åˆ†åŒºID (208=èµ„è®¯-ç¯çƒ/æ—¶æ”¿ï¼Œè¯·æ ¹æ®éœ€è¦è°ƒæ•´)
                "cover": c, 
                "title": t,
                "desc": final_desc,
                "tag": final_tag,
                "dtime": dt,              # å®šæ—¶å‘å¸ƒæ—¶é—´æˆ³
                "open-elec": 1,           # å¼€å¯å……ç”µ
            }
            
            # å¦‚æœæ˜¯ä»˜è´¹å†…å®¹ï¼Œæ·»åŠ ä»˜è´¹å­—æ®µ
            if is_paid:
                entry.update({
                    "charging_pay": 1, 
                    "upower_level_id": "1212996740244948080" # ğŸ”´ è¯·ç¡®è®¤è¿™æ˜¯æ‚¨çš„å……ç”µè®¡åˆ’ ID
                })
                
            streamers[v] = entry

        # 5. å†™å…¥æ–‡ä»¶
        try:
            with open(filename, 'w', encoding='utf-8') as f:
                # allow_unicode=True ä¿è¯ä¸­æ–‡æ­£å¸¸æ˜¾ç¤ºï¼Œsort_keys=False ä¿æŒå­—æ®µé¡ºåº
                yaml.dump({"submit": "App", "streamers": streamers}, f, allow_unicode=True, sort_keys=False)
            print(f"ğŸ“„ å·²ç”Ÿæˆé…ç½®æ–‡ä»¶: {filename} (åŒ…å« {len(sub_v)} ä¸ªè§†é¢‘)")
        except Exception as e:
            print(f"âŒ å†™å…¥ YAML å¤±è´¥ ({filename}): {e}")

    # --- æ‰§è¡Œåˆ†å‰²ä¸å†™å…¥ ---
    
    # åˆ’åˆ†ç´¢å¼•
    f_idx = indices[:split_point] # å…è´¹éƒ¨åˆ†ç´¢å¼•
    p_idx = indices[split_point:] # ä»˜è´¹éƒ¨åˆ†ç´¢å¼•
    
    # ç”Ÿæˆå…è´¹å†…å®¹çš„ YAML
    write_yaml(
        [videos[i] for i in f_idx], 
        [covers[i] for i in f_idx], 
        [titles[i] for i in f_idx], 
        [dtimes[i] for i in f_idx], 
        str(Path(PROJECT_ROOT) / 'free_content.yaml'),
        False
    )
    
    # ç”Ÿæˆä»˜è´¹å†…å®¹çš„ YAML (å¦‚æœæœ‰çš„è¯)
    if p_idx:
        write_yaml(
            [videos[i] for i in p_idx], 
            [covers[i] for i in p_idx], 
            [titles[i] for i in p_idx], 
            [dtimes[i] for i in p_idx], 
            'paid_content.yaml', 
            True
        )
# ==================== 5. ä¸»ç¨‹åº ====================

def main():
    """
    æ‰«æ storage/ready_to_publish ä¸‹çš„å­æ–‡ä»¶å¤¹ï¼Œ
    æ¯ä¸ªå­æ–‡ä»¶å¤¹åå³ä¸ºå·²ç¿»è¯‘çš„æ ‡é¢˜ï¼Œå†…å« {title}.mp4 å’Œ {title}.jpgã€‚
    ç”Ÿæˆ free_content.yaml ä¾› biliup ä½¿ç”¨ã€‚
    """
    from pathlib import Path
    import sys

    ready_dir = Path(OUTPUT_DIR)
    if not ready_dir.exists():
        print(f"âŒ ç›®å½•ä¸å­˜åœ¨: {ready_dir}")
        return

    # æ‰«æå­æ–‡ä»¶å¤¹ï¼Œæ‰¾åˆ°åŒ…å« .mp4 çš„æœ‰æ•ˆè§†é¢‘æ–‡ä»¶å¤¹
    video_entries = []  # [(video_path, cover_path, folder_name)]
    for folder in sorted(ready_dir.iterdir()):
        if not folder.is_dir():
            continue
        # è·³è¿‡ done / failed å½’æ¡£æ–‡ä»¶å¤¹
        if folder.name in ("done", "failed"):
            continue
        
        # æ‰¾ .mp4ï¼ˆæ–‡ä»¶åä¸æ–‡ä»¶å¤¹åç›¸åŒï¼‰
        mp4_files = list(folder.glob("*.mp4"))
        if not mp4_files:
            continue
        video_path = mp4_files[0]

        # æ‰¾å°é¢ .jpg
        jpg_files = list(folder.glob("*.jpg"))
        cover_path = str(jpg_files[0]) if jpg_files else ""

        video_entries.append((str(video_path), cover_path, folder.name))

    if not video_entries:
        print(f"âŒ åœ¨ {ready_dir} ä¸‹æœªå‘ç°ä»»ä½•è§†é¢‘æ–‡ä»¶å¤¹")
        return

    print(f"ğŸ“‚ å‘ç° {len(video_entries)} ä¸ªè§†é¢‘ï¼Œå¼€å§‹ç”Ÿæˆ Bç«™ YAML é…ç½®...")

    videos   = [e[0] for e in video_entries]
    covers   = [e[1] for e in video_entries]
    # æ–‡ä»¶å¤¹åå·²ç»æ˜¯ç¿»è¯‘å¥½çš„ä¸­æ–‡æ ‡é¢˜ï¼Œç›´æ¥åŠ å‰ç¼€
    titles   = [f"[ç†Ÿè‚‰]{e[2]}" for e in video_entries]  # ä¿®å¤ï¼šBç«™æ ‡é¢˜ä¸Šé™ 80 å­—

    # å®šæ—¶å‘å¸ƒæ—¶é—´ï¼šæ˜å¤© 8:00 èµ·ï¼Œæ¯éš” 45 åˆ†é’Ÿä¸€ä¸ª
    start_time = (
        datetime.now(timezone(timedelta(hours=8)))
        .replace(hour=8, minute=0, second=0, microsecond=0)
        + timedelta(days=1)
    )
    dtimes = [
        int((start_time + timedelta(minutes=45 * i)).timestamp())
        for i in range(len(videos))
    ]

    # æ‰“å°é¢„è§ˆ
    print("\nğŸ“‹ ä¸Šä¼ é¢„è§ˆï¼š")
    for i, (v, c, t, dt) in enumerate(zip(videos, covers, titles, dtimes)):
        sched = datetime.fromtimestamp(dt).strftime("%m-%d %H:%M")
        print(f"  [{i+1}] {t[:40]}...")
        print(f"       è§†é¢‘: {v}")
        print(f"       å°é¢: {c or '(æ— )'}")
        print(f"       å®šæ—¶: {sched}")

    # ç”Ÿæˆ YAMLï¼ˆå…¨éƒ¨ä½œä¸ºå…è´¹å†…å®¹ï¼‰
    split_and_create_yaml(videos, covers, titles, dtimes, paid_ratio=0.0)

    # ==================== è‡ªåŠ¨ä¸Šä¼ åˆ° B ç«™ ====================
    yaml_path    = Path(PROJECT_ROOT) / "free_content.yaml"
    cookies_path = Path(PROJECT_ROOT) / "storage" / "cookies" / "bili_cookies.json"

    print(f"\nâœ¨ YAML å·²ç”Ÿæˆ: {yaml_path}")

    # è‡ªåŠ¨æ¢æµ‹ biliup å¯æ‰§è¡Œæ–‡ä»¶è·¯å¾„
    import shutil
    biliup_bin = shutil.which("biliup") or os.path.expanduser("~/.local/bin/biliup")

    if not os.path.isfile(biliup_bin):
        print(f"âŒ æœªæ‰¾åˆ° biliup å¯æ‰§è¡Œæ–‡ä»¶ï¼ˆå·²æŸ¥æ‰¾: {biliup_bin}ï¼‰")
        print(f"   è¯·æ‰‹åŠ¨è¿è¡Œ: biliup upload -c {yaml_path} -u {cookies_path}")
        return

    if not cookies_path.exists():
        print(f"âŒ æœªæ‰¾åˆ° B ç«™ Cookies æ–‡ä»¶: {cookies_path}")
        return

    cmd = [biliup_bin, "-u", str(cookies_path), "upload", "-c", str(yaml_path)]
    print(f"\nğŸš€ å¼€å§‹ä¸Šä¼ åˆ° B ç«™...")
    print(f"   å‘½ä»¤: {' '.join(cmd)}\n")

    import subprocess
    result = subprocess.run(cmd, cwd=str(PROJECT_ROOT))

    if result.returncode == 0:
        print("\nâœ… B ç«™ä¸Šä¼ å®Œæˆï¼")
    else:
        print(f"\nâŒ biliup é€€å‡ºç : {result.returncode}ï¼Œè¯·æ£€æŸ¥ä¸Šæ–¹æ—¥å¿—ã€‚")

if __name__ == "__main__":
    main()

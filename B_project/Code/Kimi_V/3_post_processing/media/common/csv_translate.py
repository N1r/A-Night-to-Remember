import pandas as pd
import requests
import json
import time
import re
import os
from tqdm import tqdm
from colorama import init, Fore, Style

# ==================== 0. åˆå§‹åŒ– ====================
init(autoreset=True)

# ==================== 1. é…ç½®åŒº ====================
API_KEY = 'ak_1lt5CC7fR0YP9l47On12532E7b78k'
API_BASE_URL = 'https://api.longcat.chat/openai'
API_MODEL = 'LongCat-Flash-Lite'
FILE_PATH = 'batch/tasks_setting.xlsx'

# ==================== 2. æ ¸å¿ƒæ¸…ç†é€»è¾‘ ====================
def super_clean_text(text):
    """æ¸…ç† URLã€ç¤¾äº¤åª’ä½“æ¨å¹¿ã€ç‰¹å®šåšä¸»ä¿¡æ¯ã€@æåŠã€#æ ‡ç­¾"""
    if not isinstance(text, str): return ""
    
    # è¿›ä¸€æ­¥æ‹“å±•çš„åˆ é™¤æ•´è¡Œæ¨å¹¿å†…å®¹
    garbage_patterns = [
        # 1. é¢‘é“ä¼šå‘˜ä¸èµåŠ©
        r'^.*(Become a Member|Join this channel|Support the channel|Patreon|PayPal|Donation).*$',
        r'^\s*(åŠ å…¥ä¼šå‘˜|æˆä¸ºä¼šå‘˜|èµåŠ©æœ¬é¢‘é“|æ”¯æŒä½œè€…).*$',

        # 2. ç¤¾äº¤åª’ä½“å…¨å®¶æ¡¶ (æ–°å¢ Brian Tyler Cohen ç›¸å…³åŠæ›´å¤šå¹³å°)
        r'^(Instagram|Facebook|FB|Reddit|Discord|Threads|Bluesky|Substack|Twitter|X|Telegram|TG|TikTok|WhatsApp|Twitch|Spotify|Apple Podcasts)[:ï¼š\s]?.*$',
        r'^.*(Follow me on|Follow us|Connect with us|For more from).*$',
        r'^.*(Brian Tyler Cohen|å¸ƒè±æ©Â·æ³°å‹’Â·ç§‘æ©).*$',
        r'^.*(Straight-news).*$',

        # 3. è®¢é˜…ä¸å¯¼æµ (æ–°å¢ä¹¦ç±ã€é€šè®¯è®¢é˜…)
        r'^\s*[\U00010000-\U0010ffff]?\s*(è®¢é˜…|ç‚¹å‡»è®¢é˜…|æ¬¢è¿è®¢é˜…|è·å–|å…³æ³¨|Subscribe|è®¢è´­).*$',
        r'^.*(Newsletter|NYT bestselling book|ç•…é”€ä¹¦|é€šè®¯è®¢é˜…).*$',

        # 4. å•†ä¸šåˆä½œä¸è”ç³»æ–¹å¼
        r'^.*(Business inquiries|Contact me|åˆä½œé‚€çº¦|å•†åŠ¡åˆä½œ).*$',
        r'^.*(Get my book|My merch|å‘¨è¾¹å•†å“).*$',

        # 5. å¸¸è§ç»“å°¾åºŸè¯
        r'^(æ›´å¤šå†…å®¹è¯·è§|æ›´å¤šèµ„è®¯|äº†è§£æ›´å¤š|Read more|Related videos).*$',
        r'^.*(All rights reserved|ç‰ˆæƒæ‰€æœ‰).*$'
    ]   
    
    for pattern in garbage_patterns:
        text = re.sub(pattern, '', text, flags=re.IGNORECASE | re.MULTILINE)

    # B. åˆ é™¤æ‰€æœ‰ URL (å«æ‹¬å·å†…åŠæ–­å¤´é“¾æ¥)
    text = re.sub(r'https?://\S+|www\.\S+|https?:/\s?$', '', text)
    
    # C. åˆ é™¤ @æåŠ å’Œ #æ ‡ç­¾
    text = re.sub(r'@[\w\.-]+', '', text)
    text = re.sub(r'#\S+', '', text)

    # D. æ ¼å¼ä¿®æ­£
    text = text.replace('()', '').replace('ï¼ˆï¼‰', '')
    text = re.sub(r'\n\s*\n', '\n', text) 
    return re.sub(r'\s+', ' ', text).strip()

# ==================== 3. ç¿»è¯‘é€»è¾‘ ====================
def translate_batch_20(text_dict: dict) -> dict:
    """æ‰¹é‡ç¿»è¯‘ï¼Œè¿½æ±‚åœ°é“ä¸­æ–‡è¡¨è¾¾"""
    if not text_dict: return {}
    
    headers = {
        "Content-Type": "application/json",
    }
    if API_KEY:
        k = API_KEY.strip()
        if k.lower().startswith("bearer "):
            headers["Authorization"] = k
        else:
            headers["Authorization"] = f"Bearer {k}"
    else:
        print("âš ï¸ æœªæ£€æµ‹åˆ° LONGCAT API keyï¼ŒAuthorization å¤´ä¸ºç©º")
    
    prompt = f"""
    # Role
    ä½ æ˜¯ä¸€ä½èµ„æ·±å›½é™…æ–°é—»ç¼–è¾‘ï¼Œæ“…é•¿å°†å¤–è¯­å†…å®¹åœ°é“åœ°è½¬åŒ–ä¸ºç¬¦åˆä¸­æ–‡æ¯è¯­é€»è¾‘çš„çŸ­è¯„ã€‚

    # Task
    å°† JSON ä¸­çš„ Value ç¿»è¯‘æˆä¸­æ–‡ã€‚ä¿æŒ Key ä¸å˜ï¼Œä»…è¿”å› JSON å¯¹è±¡ã€‚

    # Principles
    1. **ä¿¡è¾¾é›…**ï¼šæ‹’ç»ç”Ÿç¡¬ç›´è¯‘ï¼Œæ ¹æ®ä¸­æ–‡ä¹ æƒ¯è°ƒæ•´è¯­åºå’Œé£è¯é€ å¥ã€‚
    2. **ä¸“ä¸šåº¦**ï¼šä½¿ç”¨æ­£å¼ã€åœ°é“çš„æ–°é—»ç”¨è¯­ï¼Œé¿å…å£æ°´è¯ã€‚
    3. **ç®€æ´æ€§**ï¼šåœ¨ä¿ç•™åŸæ„åŸºç¡€ä¸Šï¼Œè¡¨è¾¾è¦å¹²ç»ƒæœ‰åŠ›åº¦ã€‚

    # Data
    {json.dumps(text_dict, ensure_ascii=False)}
    """
    
    data = {
        "model": API_MODEL,
        "messages": [{"role": "user", "content": prompt}],
        "response_format": {"type": "json_object"},
        "temperature": 0.3,
        "max_tokens": 4096
    }

    try:
        response = requests.post(f"{API_BASE_URL}/v1/chat/completions", headers=headers, json=data, timeout=60)
        response.raise_for_status()
        content = response.json()["choices"][0]["message"]["content"].strip()
        
        # æå– JSON å†…å®¹
        start, end = content.find("{"), content.rfind("}")
        if start != -1 and end != -1:
            content = content[start : end + 1]
        return json.loads(content)
    except Exception as e:
        # å¤±è´¥è¿”å›ç‰¹æ®Šæ ‡è®°ï¼Œä»¥ä¾¿åç»­å‰”é™¤
        return {k: "FAIL_TO_TRANSLATE" for k in text_dict.keys()}

# ==================== 4. ä¸»ç¨‹åº ====================

def main():
    if not os.path.exists(FILE_PATH):
        print(f"{Fore.RED}âŒ æ‰¾ä¸åˆ°ä»»åŠ¡æ–‡ä»¶: {FILE_PATH}")
        return

    # è¯»å–åŸå§‹æ•°æ®
    try:
        df = pd.read_excel(FILE_PATH)
    except Exception as e:
        print(f"{Fore.RED}âŒ è¯»å– Excel å¤±è´¥: {e}")
        return

    initial_count = len(df)

    # 1. åˆå§‹åŒ–ç¿»è¯‘åˆ—ï¼ˆå¦‚æœä¸å­˜åœ¨åˆ™åˆ›å»ºï¼‰
    if 'translated_text' not in df.columns:
        df['translated_text'] = ""
    
    # 2. é¢„å¤„ç†ï¼šæ¸…æ´—æ–‡æœ¬ï¼Œä½†ä¸å¯¹ df è¿›è¡Œå‰”é™¤æ“ä½œ
    print(f"{Fore.CYAN}ğŸ§¹ æ­£åœ¨æ¸…æ´—æ–‡æœ¬å™ªéŸ³ (URL/Tags/æ¨å¹¿)...")
    df['rawtext'] = df['rawtext'].apply(super_clean_text)
    
    # å¡«å……ç©ºå€¼ï¼Œç¡®ä¿åç»­é€»è¾‘æ­£å¸¸
    df['translated_text'] = df['translated_text'].fillna("").astype(str)

    # 3. è¯†åˆ«å¾…ç¿»è¯‘è¡Œ (æ–­ç‚¹ç»­ä¼ é€»è¾‘)
    # åªå¤„ç†ï¼šç¿»è¯‘ä¸ºç©ºã€æˆ–ä¹‹å‰æ ‡è®°ä¸ºå¤±è´¥çš„è¡Œ
    mask = (df['translated_text'].str.strip() == "") | (df['translated_text'] == "FAIL_TO_TRANSLATE")
    indices_to_translate = df[mask].index.tolist()
    
    if not indices_to_translate:
        print(f"{Fore.GREEN}âœ… æ‰€æœ‰è¡Œå‡å·²å®Œæˆç¿»è¯‘ï¼Œæ— éœ€é‡å¤æ“ä½œã€‚")
        return

    # 4. æ‰§è¡Œæ‰¹é‡ç¿»è¯‘
    batch_size = 20
    print(f"{Fore.MAGENTA}ğŸš€ å¯åŠ¨ LongCat æ‰¹é‡ç¿»è¯‘ | å¾…å¤„ç†: {len(indices_to_translate)} / {initial_count} è¡Œ")

    with tqdm(total=len(indices_to_translate), desc="ç¿»è¯‘è¿›åº¦", unit="è¡Œ") as pbar:
        for i in range(0, len(indices_to_translate), batch_size):
            current_batch = indices_to_translate[i : i + batch_size]
            
            # æ„é€ æœ¬æ¬¡è½½è·
            payload = {}
            for idx in current_batch:
                text = str(df.at[idx, 'rawtext']).strip()
                if text:
                    payload[str(idx)] = text
                else:
                    # å¦‚æœæ¸…æ´—åæ–‡æœ¬å˜ç©ºäº†ï¼Œæˆ‘ä»¬è®°å½•ä¸ºè·³è¿‡ï¼Œè€Œä¸æ˜¯åˆ é™¤æ•´è¡Œ
                    df.at[idx, 'translated_text'] = "empty"

            # è°ƒç”¨æ¥å£
            if payload:
                results = translate_batch_20(payload)
                for idx_str, trans in results.items():
                    idx_int = int(idx_str)
                    # æ— è®ºæˆåŠŸå¤±è´¥ï¼Œéƒ½åªæ“ä½œ 'translated_text' å•å…ƒæ ¼
                    # å¦‚æœæ¥å£è¿”å› FAIL_TO_TRANSLATEï¼Œä¹Ÿä¼šå†™å…¥å•å…ƒæ ¼ä»¥ä¾¿ä¸‹æ¬¡é‡è¯•
                    df.at[idx_int, 'translated_text'] = trans
            
            pbar.update(len(current_batch))
            # é€‚å½“é™é€Ÿï¼Œä¿æŠ¤ API
            time.sleep(0.3)

    # 5. ä¿å­˜å¹¶è¦†ç›–åŸæ–‡ä»¶ (ä¸å†æ‰§è¡Œä»»ä½• df.drop æˆ–è¿‡æ»¤)
    try:
        # ä½¿ç”¨åŸæ–‡ä»¶åè¦†ç›–ä¿å­˜ï¼Œä¿ç•™æ‰€æœ‰è¡Œå’ŒåŸå§‹åˆ—
        df.to_excel(FILE_PATH, index=False)
        
        success_count = len(df[df['translated_text'].str.strip() != ""])
        print(f"\n{Fore.GREEN}âœ¨ å¤„ç†å®Œæˆï¼")
        print(f"{Fore.WHITE}ğŸ“Š è¡¨æ ¼æ€»è¡Œæ•°: {initial_count} (å·²å…¨éƒ¨ä¿ç•™)")
        print(f"{Fore.CYAN}âœ… å·²ç¿»è¯‘æˆåŠŸè¡Œæ•°: {success_count}")
        print(f"ğŸ“‚ æ–‡ä»¶å·²æ›´æ–°: {FILE_PATH}")
    except PermissionError:
        print(f"{Fore.RED}âŒ è¦†ç›–å¤±è´¥ï¼è¯·å…ˆå…³é—­ Excel æ–‡ä»¶: {FILE_PATH} åå†è¿è¡Œè„šæœ¬ã€‚")
    except Exception as e:
        print(f"{Fore.RED}âŒ ä¿å­˜è¿‡ç¨‹å‡ºé”™: {e}")

if __name__ == "__main__":
    main()
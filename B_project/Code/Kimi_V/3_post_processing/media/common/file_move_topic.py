import os
import re
import shutil
import json
import pandas as pd
from pathlib import Path
from datetime import datetime
from rapidfuzz import fuzz, process
import requests

# ==================== é…ç½®åŒº ====================
API_KEY = os.environ.get("LONGCAT_API_KEY", "ak_1lt5CC7fR0YP9l47On12532E7b78k")
API_BASE_URL = 'https://api.longcat.chat/openai'
API_MODEL = 'LongCat-Flash-Chat'

# ==================== è·¯å¾„é…ç½® ====================
# è·å–é¡¹ç›®æ ¹ç›®å½• (è¯¥æ–‡ä»¶åœ¨ 3_post_processing/media/common/ ä¸‹ï¼Œæ·±åº¦ä¸º 4 å±‚)
PROJECT_ROOT = Path(__file__).parent.parent.parent.parent.absolute()
SOURCE_DIR = PROJECT_ROOT / "storage" / "ready_to_publish" 
TARGET_DIR = PROJECT_ROOT / "archives"
HISTORY_FILE = PROJECT_ROOT / "storage" / "tasks" / "organized_history.json"
TASKS_EXCEL = PROJECT_ROOT / "storage" / "tasks" / "tasks_setting.xlsx"

# ==================== æ–‡ä»¶å¤„ç† ====================
def simple_read_topic(file_path: str) -> list:
    try:
        with open(file_path, 'r', encoding='utf-8') as f:
            data = json.load(f)
        return [item['response']['topic'] for item in data if 'response' in item and 'topic' in item['response']]
    except Exception:
        return []

def quick_read_srt(file_path: str) -> str:
    """æç®€è¯»å– SRT çº¯æ–‡æœ¬"""
    if not os.path.exists(file_path):
        return ""
    with open(file_path, 'r', encoding='utf-8-sig', errors='ignore') as f:
        content = f.read()
    
    pattern = r'\d{2}:\d{2}:\d{2},\d{3} --> \d{2}:\d{2}:\d{2},\d{3}'
    lines = [
        line.strip() for line in content.splitlines() 
        if line.strip() and not line.strip().isdigit() and not re.match(pattern, line)
    ]
    return "\n".join(lines)

def sanitize_filename(filename):
    """æ¸…ç†æ–‡ä»¶åï¼Œç¡®ä¿ç¬¦åˆç³»ç»Ÿè§„èŒƒä¸”ä¸å«éæ³•å­—ç¬¦"""
    if not filename: return "untitled"
    filename = re.sub(r'[\\/:*?\"<>|#\n\r\t]', '_', str(filename))
    return filename.strip()[:100]

# ==================== API ä¸ç¿»è¯‘ ====================
def translate_with_api(text: str) -> str:
    headers = {
        "Authorization": f"Bearer {API_KEY}",
        "Content-Type": "application/json",
    }
    prompt = """ä½ æ˜¯ä¸€åèµ„æ·±æ”¿ç»ä¸»ç¬”ã€‚è¯·ä»æä¾›çš„å†…å®¹ä¸­æå–æœ€å…·å†²å‡»åŠ›çš„æ ¸å¿ƒè¯­å½•ï¼Œå¹¶é‡å¡‘ä¸ºä¸€ä¸ªå¸å¼•äººçš„ä¸­æ–‡æ ‡é¢˜ã€‚æ ¼å¼ï¼šäººç‰©ï¼šâ€œè¯­å½•â€ æè¿°ã€‚ä»…è¾“å‡ºä¸€è¡Œã€‚"""
    data = {
        "model": API_MODEL,
        "messages": [
            {"role": "system", "content": prompt},
            {"role": "user", "content": text}
        ],
        "stream": False,
    }
    try:
        response = requests.post(f"{API_BASE_URL}/v1/chat/completions", headers=headers, json=data, timeout=30)
        response.raise_for_status()
        return response.json()["choices"][0]["message"]["content"].strip()
    except Exception as e:
        print(f"  âš ï¸ API è¯·æ±‚å¤±è´¥: {e}")
        return None

def _normalize_for_match(text: str) -> str:
    """å°†æ–‡æœ¬è§„èŒƒåŒ–ï¼šå»é™¤æ ‡ç‚¹ã€ç‰¹æ®Šå­—ç¬¦ã€å¤šä½™ç©ºæ ¼ï¼Œç»Ÿä¸€å°å†™ï¼Œç”¨äºåŒ¹é…æ¯”è¾ƒ"""
    text = re.sub(r'https?://\S+', '', text)           # å»é™¤ URL
    text = re.sub(r'[^\w\s]', ' ', text)               # å»é™¤æ‰€æœ‰æ ‡ç‚¹ç¬¦å·
    text = re.sub(r'\s+', ' ', text).strip().lower()    # åˆå¹¶ç©ºæ ¼å¹¶å°å†™
    return text

def get_channel_info(file_path, target_name):
    """é€šè¿‡æ¨¡ç³ŠåŒ¹é…æ–‡ä»¶å¤¹åï¼Œè·å– Excel ä¸­å¯¹åº”çš„é¢‘é“åã€æè¿°å’Œ AI æ ‡é¢˜ã€‚

    åŒ¹é…ç­–ç•¥ï¼ˆä¼˜å…ˆçº§ä»é«˜åˆ°ä½ï¼‰ï¼š
      1. åŒ¹é… `title` åˆ—ï¼ˆStep 1 ç”Ÿæˆçš„ä¸­æ–‡æ ‡é¢˜ï¼Œä¸æ–‡ä»¶å¤¹ååŒæºï¼‰
      2. åŒ¹é… `rawtext` åˆ—ï¼ˆåŸå§‹è‹±æ–‡æ¨æ–‡ï¼Œå…œåº•ï¼‰
    """
    try:
        if not os.path.exists(file_path):
            return {"channel_name": "ç²¾é€‰æ–°é—»", "description": "æš‚æ— æè¿°", "ai_title": None}

        df = pd.read_excel(file_path)
        normalized_target = _normalize_for_match(target_name)

        def _try_match(col: str, threshold: int = 75):
            if col not in df.columns:
                return None, None
            choices_raw = df[col].astype(str).tolist()
            choices_norm = [_normalize_for_match(c) for c in choices_raw]
            m = process.extractOne(
                normalized_target,
                choices_norm,
                scorer=fuzz.token_set_ratio,
            )
            if m and m[1] >= threshold:
                idx = choices_norm.index(m[0])
                return idx, m[1]
            return None, m[1] if m else 0

        # 1. å…ˆåŒ¹é…ä¸­æ–‡ title åˆ—ï¼ˆæ–‡ä»¶å¤¹åä¸ title_cn åŒæºï¼Œå‘½ä¸­ç‡é«˜ï¼‰
        idx, score = _try_match("title", threshold=75)
        col_used = "title"

        # 2. è‹¥ title åˆ—åŒ¹é…å¤±è´¥ï¼Œå†å°è¯• rawtext åˆ—
        if idx is None:
            idx2, score2 = _try_match("rawtext", threshold=80)
            if idx2 is not None:
                idx, score, col_used = idx2, score2, "rawtext"

        if idx is not None:
            row = df.iloc[idx]
            display = str(df[col_used].iloc[idx])[:60]
            print(f"  ğŸ“ Excel åŒ¹é…æˆåŠŸ [{col_used}] (score={score:.0f}): {display}...")
            return {
                "channel_name": row.get('channel_name', 'ç²¾é€‰æ–°é—»'),
                "description": row.get('rawtext', 'æš‚æ— æè¿°'),
                "ai_title": row.get('title', None),
                "original_link": row.get('Video File', ''),
                "ai_reason": row.get('AI Reason', ''),
                "category": row.get('Category', ''),
                "publish_date": row.get('Publish Date', ''),
                "translated_text": row.get('translated_text', ''),
                "suitability_score": row.get('Score', 'N/A'),
                "source_lang": row.get('Source Language', 'en'),
                "target_lang": row.get('Target Language', 'zh-CN')
            }
        else:
            print(f"  âš ï¸ Excel æœªæ‰¾åˆ°åŒ¹é…é¡¹ (best={score:.0f})")
    except Exception as e:
        print(f"  âš ï¸ Excel è¯»å–å¼‚å¸¸: {e}")
    return {"channel_name": "ç²¾é€‰æ–°é—»", "description": "æš‚æ— æè¿°", "ai_title": None}

def process_and_move_files():
    """ä¸»ç¨‹åºï¼šæ•´ç† -> é‡å‘½å -> å½’æ¡£"""
    print(f"ğŸš€ å¼€å§‹æ‰§è¡Œæ•´ç†ä»»åŠ¡...")
    TARGET_DIR.mkdir(parents=True, exist_ok=True)
    HISTORY_FILE.parent.mkdir(parents=True, exist_ok=True)

    history = {}
    if HISTORY_FILE.exists():
        try:
            history = json.loads(HISTORY_FILE.read_text(encoding='utf-8'))
        except Exception:
            pass

    folders = [
        f for f in SOURCE_DIR.iterdir() 
        if f.is_dir() and f.name.upper() not in ["ERROR", "DONE", "FAILED", "ORGANIZED", "TEST_VIDEO_AUTO_IGNORE"]
    ]
    
    print(f"ğŸ“Š å‘ç° {len(folders)} ä¸ªå¾…æ•´ç†ä»»åŠ¡")
    
    for folder in folders:
        folder_name = folder.name
        if not (folder / "output_sub.mp4").exists(): continue
        if folder_name in history: continue

        print(f"\n--- æ­£åœ¨æ•´ç†: {folder_name} ---")
        try:
            info = get_channel_info(TASKS_EXCEL, folder_name)
            raw_title = info.get('ai_title')
            
            # æå‰å‡†å¤‡ topic_list é˜²æ­¢ NameError
            topic_list = []
            json_path = folder / 'gpt_log' / 'summary.json'
            if json_path.exists():
                topic_list = simple_read_topic(str(json_path))

            if not raw_title:
                print(f"  âš ï¸ Excel ä¸­æœªæ‰¾åˆ° AI æ ‡é¢˜ï¼Œå°è¯•å³æ—¶ç”Ÿæˆ...")
                srt_content = quick_read_srt(str(folder / 'trans.srt'))
                # ä½¿ç”¨ topic_list å¢å¼ºç”Ÿæˆæ•ˆæœ
                raw_title = translate_with_api(f"Original Title: {folder_name}\nTopics: {topic_list}\nTranscript: {srt_content[:1000]}")
            
            if not raw_title:
                raw_title = folder_name
                
            safe_title = sanitize_filename(raw_title)
            topic_folder = TARGET_DIR / safe_title
            topic_folder.mkdir(parents=True, exist_ok=True)
            
            # æ‹·è´è§†é¢‘
            shutil.copy2(str(folder / "output_sub.mp4"), str(topic_folder / f"{safe_title}.mp4"))
            
            # æ‹·è´å°é¢
            cover = next(folder.glob("*_new*.*"), None) or next(folder.glob("*.jpg"), None)
            if cover:
                shutil.copy2(str(cover), str(topic_folder / f"{safe_title}{cover.suffix}"))
            
            meta_data = {
                "original_topic": folder_name,
                "translated_title": raw_title,
                "organize_time": datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
                "channel": info.get('channel_name', ""),
                "src_folder": str(folder),
                "original_link": info.get('original_link', ''),
                "ai_reason": info.get('ai_reason', ''),
                "category": info.get('category', ''),
                "publish_date": str(info.get('publish_date', '')),
                "translated_text": info.get('translated_text', '')
            }
            (topic_folder / "metadata.json").write_text(json.dumps(meta_data, ensure_ascii=False, indent=2))
            
            # ä¸¾ä¸€åä¸‰ï¼šæ„å»ºå†…å®¹æå…¶è¯¦å°½çš„äººç±»å¯è¯» metadata.txt
            score_val = info.get('suitability_score', 'N/A')
            if isinstance(score_val, (int, float)) and score_val > 1000:
                score_display = f"{score_val/1000:.1f} (AIæ ¸å¿ƒåˆ†)"
            else:
                score_display = str(score_val)

            metadata_txt = f"""VideoLingo è§†é¢‘å‘å¸ƒå­˜æ¡£æŠ¥å‘Š
================================================================================
ã€æ ¸å¿ƒä¿¡æ¯ã€‘
ä¸­æ–‡æ ‡é¢˜: {raw_title}
å†…å®¹åˆ†ç±»: {info.get('category', 'æœªåˆ†ç±»')}
è¯„ä¼°åˆ†å€¼: {score_display}
æ¨èç†ç”±: {info.get('ai_reason', 'æ— ')}

--------------------------------------------------------------------------------
ã€åŸå§‹æ¨æ–‡å†…å®¹ã€‘
{info.get('description', 'æ— ')}

ã€æ¨æ–‡ä¸­æ–‡ç¿»è¯‘ã€‘
{info.get('translated_text', 'ï¼ˆæš‚æ— ç¿»è¯‘ï¼‰')}

--------------------------------------------------------------------------------
ã€æº¯æºä¸æŠ€æœ¯ä¿¡æ¯ã€‘
åŸå§‹é“¾æ¥: {info.get('original_link', 'æ— ')}
å‘å¸ƒæ—¥æœŸ: {info.get('publish_date', 'æ— ')}
é‡‡é›†é¢‘é“: {info.get('channel_name', 'æœªçŸ¥')}
æºè¯­è¨€: {info.get('source_lang', 'en')} -> {info.get('target_lang', 'zh-CN')}
åŸå§‹ç´ æç›®å½•: {folder_name}
ç‰©ç†æ•´ç†è·¯å¾„: {str(topic_folder)}
æ•´ç†æ—¶é—´: {meta_data['organize_time']}
================================================================================
"""
            (topic_folder / "metadata.txt").write_text(metadata_txt, encoding='utf-8')
            history[folder_name] = meta_data
            HISTORY_FILE.write_text(json.dumps(history, ensure_ascii=False, indent=2))
            print(f"  âœ¨ æ•´ç†å®Œæˆ: {safe_title}")

        except Exception as e:
            print(f"  âŒ å‡ºé”™: {e}")
            continue

if __name__ == "__main__":
    process_and_move_files()

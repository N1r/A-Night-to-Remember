"""
workflow_2_mid.py
-----------------
é˜¶æ®µ 2ï¼šè§†é¢‘å¤„ç†å·¥ä½œæµï¼ˆPipeline æ¨¡å¼ï¼‰ã€‚

æ ¸å¿ƒå¤„ç†é“¾ï¼š
  1. yt-dlp ä¸‹è½½è§†é¢‘
  2. ASR è¯­éŸ³è¯†åˆ«
  3. NLP å¥å­åˆ‡åˆ†
  4. è¯­ä¹‰åˆ‡åˆ†
  5. æ‘˜è¦ + æœ¯è¯­æå–
  6. å…¨æ–‡ç¿»è¯‘
  7. å­—å¹•åˆ‡åˆ†å¯¹é½
  8. ASS/SRT æ—¶é—´è½´ç”Ÿæˆ
  9. FFmpeg å­—å¹•å‹åˆ¶
  10. å°é¢æå–
  11. å½’æ¡£åˆ° ready_to_publish

è¿è¡Œæ–¹å¼ï¼š
    python 2_mid_processing/workflow_2_mid.py
    python 2_mid_processing/workflow_2_mid.py --max=5   # æ‰¹é‡å¤„ç† 5 ä¸ª
"""

import argparse
import os
import shutil
import subprocess
import sys
import pandas as pd
from pathlib import Path

# ==================== è·¯å¾„è®¾ç½® ====================
PROJECT_ROOT = Path(__file__).parent.parent.absolute()
if str(PROJECT_ROOT) not in sys.path:
    sys.path.insert(0, str(PROJECT_ROOT))

sys.path.insert(0, str(Path(__file__).parent))  # ç¡®ä¿ core/ å¯å¯¼å…¥

from shared.paths import TASKS_EXCEL, READY_DIR, OUTPUT_DIR as GLOBAL_OUTPUT
from shared.logger import console, log_step, Panel


# ==================== Pipeline å®šä¹‰ ====================

class Pipeline:
    """
    è§†é¢‘å¤„ç† Pipeline â€” é¡ºåºæ‰§è¡Œä¸€ç³»åˆ—æ­¥éª¤ã€‚

    æ¯ä¸ªæ­¥éª¤æ˜¯ä¸€ä¸ª (name, callable) å…ƒç»„ã€‚
    å¦‚æœæŸä¸€æ­¥å¤±è´¥ï¼Œå¯é€‰æ‹©è·³è¿‡æˆ–ç»ˆæ­¢ã€‚
    """

    def __init__(self, steps: list = None):
        self.steps = steps or []

    def add(self, name: str, func):
        self.steps.append((name, func))
        return self

    def run(self, fail_fast: bool = True) -> list:
        """
        ä¾æ¬¡æ‰§è¡Œæ‰€æœ‰æ­¥éª¤ã€‚

        Returns
        -------
        list : æ¯æ­¥çš„ (name, success: bool, error: str|None) ä¸‰å…ƒç»„
        """
        results = []
        for i, (name, func) in enumerate(self.steps, 1):
            log_step(i, name, "running")
            try:
                func()
                log_step(i, name, "done")
                results.append((name, True, None))
            except Exception as e:
                log_step(i, name, "failed")
                console.print(f"[red]   âŒ é”™è¯¯: {e}[/red]")
                results.append((name, False, str(e)))
                if fail_fast:
                    break
        return results


# ==================== æ ¸å¿ƒå¤„ç†å‡½æ•° ====================

def _build_pipeline():
    """
    æ„å»ºè§†é¢‘å¤„ç† Pipelineã€‚

    å°† core/ ç›®å½•ä¸‹çš„å„æ¨¡å—æŒ‰åºç¼–æ’ï¼š
        download â†’ ASR â†’ split â†’ translate â†’ subtitle â†’ encode
    """
    from core._1_ytdlp import download_video_ytdlp, find_video_files
    from core._2_asr import transcribe
    from core._3_1_split_nlp import split_by_spacy
    from core._3_2_split_meaning import split_sentences_by_meaning
    from core._4_1_summarize import get_summary
    from core._4_2_translate import translate_all
    from core._5_split_sub import split_for_sub_main
    from core._6_gen_sub import align_timestamp_main
    from core._7_1_ass_into_vid import merge_subtitles_to_video

    pipe = Pipeline()
    pipe.add("è¯­éŸ³è¯†åˆ« (ASR)", transcribe)
    pipe.add("è‡ªç„¶è¯­è¨€åˆ‡åˆ† (NLP Split)", split_by_spacy)
    pipe.add("åŸºäºè¯­ä¹‰çš„ç²¾ç»†åˆ‡åˆ†", split_sentences_by_meaning)
    pipe.add("å†…å®¹æ‘˜è¦ä¸æœ¯è¯­æå–", get_summary)
    pipe.add("å…¨æ–‡ç¿»è¯‘", translate_all)
    pipe.add("å­—å¹•åˆ‡åˆ†ä¸å¯¹é½", split_for_sub_main)
    pipe.add("æ—¶é—´è½´æ ¡å‡†ä¸ SRT/ASS ç”Ÿæˆ", align_timestamp_main)

    return pipe


def _extract_cover(video_file: str, output_dir: str):
    """ä»è§†é¢‘ä¸­æå–å°é¢å¸§"""
    raw_cover = os.path.join(output_dir, "cover_raw.jpg")
    final_cover = os.path.join(output_dir, "cover.png")

    try:
        subprocess.run(
            ["ffmpeg", "-y", "-i", video_file, "-ss", "00:00:05", "-vframes", "1", raw_cover],
            check=True,
            capture_output=True,
        )
    except subprocess.CalledProcessError as e:
        console.print(f"[yellow]âš ï¸ ffmpeg å°é¢æå–å¤±è´¥: {e.stderr.decode(errors='replace').strip()}[/yellow]")
        return

    if os.path.exists(raw_cover):
        shutil.copy(raw_cover, final_cover)
        console.print(f"âœ¨ å°é¢å·²ä¿å­˜: {final_cover}")
    else:
        console.print("[yellow]âš ï¸ å°é¢æå–å¤±è´¥ï¼šè¾“å‡ºæ–‡ä»¶æœªç”Ÿæˆ[/yellow]")


def _archive_to_publish(title: str, output_dir: str):
    """å°†å¤„ç†ç»“æœå½’æ¡£åˆ° ready_to_publish/ï¼Œå¹¶æ¸…ç†å†—ä½™æ–‡ä»¶"""
    from core._1_ytdlp import find_video_files

    safe_title = "".join(
        [c for c in title if c.isalnum() or c in (" ", "-", "_")]
    ).strip()
    target_dir = READY_DIR / safe_title
    target_dir.mkdir(parents=True, exist_ok=True)
    
    # åˆ›å»ºé™„å±æ–‡ä»¶å¤¹æ”¶é›†ä¸­é—´äº§ç‰©
    artifacts_dir = target_dir / "artifacts"
    artifacts_dir.mkdir(exist_ok=True)

    # 1. ç§»åŠ¨æ ¸å¿ƒäº§ç‰©
    # ç§»åŠ¨åŸå§‹è§†é¢‘
    video_file = find_video_files(exit_if_multiple=False)
    if video_file:
        shutil.move(video_file, str(target_dir / ("video_raw" + os.path.splitext(video_file)[1])))

    # ç§»åŠ¨å‹åˆ¶åè§†é¢‘
    output_video = os.path.join(output_dir, "output_sub.mp4")
    if os.path.exists(output_video):
        shutil.move(output_video, str(target_dir / "output_sub.mp4"))

    # ç§»åŠ¨å°é¢
    output_cover = os.path.join(output_dir, "cover.png")
    if os.path.exists(output_cover):
        shutil.move(output_cover, str(target_dir / "cover.png"))

    # 2. ç§»åŠ¨ä¸­é—´äº§ç‰©åŠæ—¥å¿—
    # å­—å¹•æ–‡ä»¶
    for ext in ["*.srt", "*.ass"]:
        for f in Path(output_dir).glob(ext):
            shutil.move(str(f), str(artifacts_dir / f.name))

    # LOG ç›®å½•
    src_log = os.path.join(output_dir, "log")
    if os.path.exists(src_log):
        shutil.move(src_log, str(target_dir / "processing_logs"))

    # 3. æ¸…ç†å‰©ä½™çš„çç¢æ–‡ä»¶ (å¦‚ cover_raw.jpg ç­‰)
    for f in Path(output_dir).iterdir():
        if f.is_file():
            try:
                f.unlink()
            except OSError as e:
                console.print(f"[yellow]âš ï¸ æ— æ³•åˆ é™¤æ–‡ä»¶ {f.name}: {e}[/yellow]")
        elif f.is_dir() and f.name not in ["artifacts", "processing_logs"]:
            try:
                shutil.rmtree(f)
            except OSError as e:
                console.print(f"[yellow]âš ï¸ æ— æ³•åˆ é™¤ç›®å½• {f.name}: {e}[/yellow]")

    console.print(f"ğŸ“¦ å·²å½’æ¡£å¹¶æ¸…ç†å·¥ä½œåˆ†ç‰‡: [cyan]{safe_title}[/cyan]")


# ==================== å•è§†é¢‘å¤„ç† ====================

def process_single_video(url: str, title: str):
    """å¤„ç†å•ä¸ªè§†é¢‘çš„å®Œæ•´æµç¨‹"""
    console.print(
        f"\nğŸ¬ [bold magenta]å¼€å§‹å¤„ç†è§†é¢‘: {title}[/bold magenta]"
    )

    output_dir = os.path.join(str(PROJECT_ROOT), "output")

    # 1. å¼ºåŠ›æ¸…ç†å¹¶é¢„çƒ­å·¥ä½œåŒº
    if os.path.exists(output_dir):
        try:
            shutil.rmtree(output_dir)
        except Exception as e:
            console.print(f"[yellow]âš ï¸ åˆå§‹æ¸…ç†å¤±è´¥ï¼Œå°è¯•æš´åŠ›æ¸…ç†æ–‡ä»¶: {e}[/yellow]")
            # å¤‡é€‰ï¼šæ¸…ç†ç›®å½•ä¸‹æ‰€æœ‰ mp4
            for p in Path(output_dir).glob("*.mp4"):
                try:
                    p.unlink()
                except OSError:
                    pass
    
    # ç¡®ä¿ç›®å½•åŠå…¶æ‰€éœ€å­ç›®å½•å…¨éƒ¨å­˜åœ¨
    os.makedirs(output_dir, exist_ok=True)
    os.makedirs(os.path.join(output_dir, "log"), exist_ok=True)
    os.makedirs(os.path.join(output_dir, "audio"), exist_ok=True)

    # 2. ä¸‹è½½
    console.print(f"ğŸ“¥ æ­£åœ¨ä¸‹è½½: {url}")
    from core._1_ytdlp import download_video_ytdlp, find_video_files
    download_video_ytdlp(url)

    # 3. æ‰§è¡Œ Pipeline
    pipe = _build_pipeline()
    results = pipe.run(fail_fast=True)

    # æ£€æŸ¥æ˜¯å¦æœ‰å¤±è´¥æ­¥éª¤
    failed = [(name, err) for name, ok, err in results if not ok]
    if failed:
        console.print(f"[red]âŒ {len(failed)} ä¸ªæ­¥éª¤å¤±è´¥ï¼Œè·³è¿‡åç»­å¤„ç†[/red]")
        return False

    # 4. å°é¢æå–
    console.print("ğŸ¨ æ­£åœ¨æå–å°é¢...")
    try:
        video_file = find_video_files(exit_if_multiple=False)
        if video_file:
            _extract_cover(video_file, output_dir)
    except Exception as e:
        console.print(f"[yellow]âš ï¸ å°é¢æå–å¤±è´¥: {e}[/yellow]")

    # 5. å½’æ¡£
    _archive_to_publish(title, output_dir)

    console.print(f"âœ… è§†é¢‘ [cyan]{title}[/cyan] å¤„ç†å®Œæˆ")
    return True


# ==================== æ‰¹é‡å·¥ä½œæµ ====================

def mid_process_workflow():
    console.print(
        Panel.fit(
            "[bold cyan]é˜¶æ®µ 2: è§†é¢‘å¤„ç† Pipeline[/bold cyan]\n"
            "[dim]ä¸‹è½½ â†’ ASR â†’ ç¿»è¯‘ â†’ å­—å¹• â†’ å‹åˆ¶ â†’ å½’æ¡£[/dim]",
            border_style="cyan",
        )
    )

    if not TASKS_EXCEL.exists():
        console.print("[red]âŒ ä»»åŠ¡åˆ—è¡¨ä¸å­˜åœ¨ï¼Œè¯·å…ˆè¿è¡Œé˜¶æ®µ 1ã€‚[/red]")
        return

    df = pd.read_excel(TASKS_EXCEL)
    if df.empty:
        console.print("[yellow]âš ï¸ ä»»åŠ¡åˆ—è¡¨ä¸ºç©ºã€‚[/yellow]")
        return

    if "Status" not in df.columns:
        df["Status"] = ""

    pending = df[~df["Status"].isin(["done", "error"])]
    if pending.empty:
        console.print("[green]âœ… æ‰€æœ‰ä»»åŠ¡å‡å·²å®Œæˆã€‚[/green]")
        return

    # è§£æå‘½ä»¤è¡Œå‚æ•°
    parser = argparse.ArgumentParser(prog="workflow_2_mid", add_help=False)
    parser.add_argument("--max", type=int, default=10, metavar="N",
                        help="æœ¬æ¬¡æœ€å¤šå¤„ç†çš„ä»»åŠ¡æ•°ï¼ˆé»˜è®¤ 3ï¼‰")
    args, _ = parser.parse_known_args()
    max_tasks = args.max

    num_to_process = min(max_tasks, len(pending))
    console.print(
        f"ğŸ“… æœ¬æ¬¡æ‰¹é‡å¤„ç† [bold green]{num_to_process}[/bold green] ä¸ªä»»åŠ¡ "
        f"[dim](å…± {len(pending)} ä¸ªå¾…å¤„ç†)[/dim]"
    )

    processed = 0
    for idx, task in pending.iterrows():
        if processed >= num_to_process:
            break

        try:
            success = process_single_video(task["Video File"], task["title"])
            if success:
                # é‡æ–°è¯»å– Excel ä»¥é˜²å…¶ä»–è¿›ç¨‹ä¿®æ”¹ï¼ˆè™½ç„¶å½“å‰ä¸»è¦æ˜¯å•è¿›ç¨‹ï¼Œä½†è¿™æ˜¯ä¸ªå¥½ä¹ æƒ¯ï¼‰
                # è¿™é‡Œä¸ºäº†ç®€å•ç›´æ¥æ›´æ–°å†…å­˜ä¸­çš„ df å¹¶ä¿å­˜
                df.at[idx, "Status"] = "done"
                df.to_excel(TASKS_EXCEL, index=False)
                console.print(f"ğŸ“ ä»»åŠ¡çŠ¶æ€å·²æ›´æ–°ä¸º [bold green]done[/bold green]")
                processed += 1
        except Exception as e:
            console.print(f"[red]âŒ '{task['title']}' å¤„ç†å¤±è´¥: {e}[/red]")
            # è®°å½•é”™è¯¯çŠ¶æ€
            df.at[idx, "Status"] = "error"
            df.to_excel(TASKS_EXCEL, index=False)
            continue

    console.print(
        f"[bold green]âœ¨ æ‰¹é‡å¤„ç†å®Œæˆ (æˆåŠŸ: {processed}/{num_to_process})[/bold green]"
    )


if __name__ == "__main__":
    mid_process_workflow()